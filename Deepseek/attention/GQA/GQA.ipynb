{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from dataclasses import dataclass\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import math"
      ],
      "metadata": {
        "id": "bBJmMUU4WjOf"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class Config:\n",
        "  vocab_size: int = 50000\n",
        "  seq_len: int = 4096\n",
        "  d_model: int = 5120\n",
        "  n_heads: int = 32\n",
        "  kv_n_heads: int = 8\n",
        "  n_layers: int = 40\n",
        "  hidden_size: int = 14336"
      ],
      "metadata": {
        "id": "XO7qJ8UDWjLN"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GroupQueryAttentionBlock(nn.Module):\n",
        "  def __init__(self, config: Config):\n",
        "    super().__init__()\n",
        "\n",
        "    self.d_model = config.d_model\n",
        "    self.n_heads = config.n_heads\n",
        "    self.kv_n_heads = config.kv_n_heads\n",
        "    assert self.d_model % self.n_heads == 0, \"d_model must be divisible by n_heads\"\n",
        "    self.head_dim = self.d_model // self.n_heads\n",
        "\n",
        "    self.n_rep = self.n_heads // self.kv_n_heads\n",
        "\n",
        "    self.w_q = nn.Linear(self.d_model, self.n_heads * self.head_dim, bias=False)\n",
        "    self.w_k = nn.Linear(self.d_model, self.kv_n_heads * self.head_dim, bias=False)\n",
        "    self.w_v = nn.Linear(self.d_model, self.kv_n_heads * self.head_dim, bias=False)\n",
        "\n",
        "    self.w_o = nn.Linear(self.n_heads * self.head_dim, self.d_model, bias=False)\n",
        "\n",
        "  def repeat_kv(self, x, n_rep: int):\n",
        "    B, T, kv_n_heads, head_dim = x.shape\n",
        "    if n_rep == 1:\n",
        "      return x\n",
        "    x = x[:, :, :, None, :].expand(B, T, kv_n_heads, n_rep, head_dim).reshape(B, T, kv_n_heads * n_rep, head_dim)  # (B,  T, nh, hd)\n",
        "    return x\n",
        "\n",
        "  def forward(self, x, mask=None):\n",
        "    # x: (B, T, d_model)\n",
        "    # mask: (B, 1, T, T)\n",
        "\n",
        "    B, T, _ = x.shape\n",
        "    query = self.w_q(x)    # (B, T, nh * hd)\n",
        "    key = self.w_k(x)    # (B, T, kv_nh * hd)\n",
        "    value = self.w_v(x)    # (B, T, kv_nh * hd)\n",
        "\n",
        "    query = query.view(B, T, self.n_heads, self.head_dim)    # (B, T, nh, hd)\n",
        "    key = key.view(B, T, self.kv_n_heads, self.head_dim)    # (B, T, kv_nh, hd)\n",
        "    value = value.view(B, T, self.kv_n_heads, self.head_dim)    # (B, T, kv_nh, hd)\n",
        "\n",
        "    key = self.repeat_kv(key, self.n_rep)    # (B, T, nh, hd)\n",
        "    value = self.repeat_kv(value, self.n_rep)  # (B, T, nh, hd)\n",
        "\n",
        "    query = query.transpose(1, 2)    # (B, nh, T, hd)\n",
        "    key = key.transpose(1, 2)        # (B, nh, T, hd)\n",
        "    value = value.transpose(1, 2)    # (B, nh, T, hd)\n",
        "\n",
        "    attention_scores = query @ key.transpose(2, 3) / math.sqrt(self.head_dim)   # (B, nh, T, T)\n",
        "\n",
        "    # apply mask\n",
        "    if mask is not None:\n",
        "      attention_scores = attention_scores.masked_fill_(mask == 0, -1e9)\n",
        "\n",
        "    z = attention_scores @ value    # (B, nh, T, hd)\n",
        "    z = z.transpose(1, 2).contiguous().view(B, T, self.n_heads * self.head_dim)    # (B, T, nh * hd)\n",
        "\n",
        "    return self.w_o(z)    # (B, T, d_model)"
      ],
      "metadata": {
        "id": "3nbRfxAyWjHN"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def causal_mask(size):\n",
        "  mask = torch.triu(torch.ones(1, size, size), diagonal=1)\n",
        "  return mask == 0"
      ],
      "metadata": {
        "id": "cRLzgR3JWjAc"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = Config()\n",
        "mask = causal_mask(config.seq_len)\n",
        "mask = mask.unsqueeze(0)\n",
        "mask.shape  # (B, nh, T, T)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkRIff3Ge5sk",
        "outputId": "5574308f-5116-486e-b901-b8757d9f123a"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 4096, 4096])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 1\n",
        "SEQ_LEN = config.seq_len\n",
        "D_MODEL = config.d_model\n",
        "X = torch.randn(BATCH_SIZE, SEQ_LEN, D_MODEL)\n",
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BaxcHpDiJw6x",
        "outputId": "fd16d372-9b95-4cab-b596-ee637e04b1d2"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 4096, 5120])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attn = GroupQueryAttentionBlock(config)\n",
        "output = attn(X, mask)\n",
        "output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oE4SrhkiLC28",
        "outputId": "559c85f3-816b-4330-8c57-243721b267eb"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 4096, 5120])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lrJhk1OhLJLi"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome to Colaboratory",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}