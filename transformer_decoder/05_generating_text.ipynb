{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d96d735-21ae-4e54-a3a4-cc79cc7f03e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7079da3c-d0ef-4e98-bd1a-2b52a55ad929",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"vocab_size\": 50257,     # vocabulary size\n",
    "    \"context_length\": 1024,  # context length\n",
    "    \"d_model\": 768,          # Embedding dimension | hidden size\n",
    "    \"num_heads\": 12,         # Number of attention heads\n",
    "    \"num_layers\": 12,        # Number of layers\n",
    "    \"drop_rate\": 0.1,        # Dropout rate\n",
    "    \"qkv_bias\": False,       # query-key-value bias\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a691c1a7-81e8-448e-a371-2522ca07b424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4096, 4608])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, T, d_model, num_heads, drop_rate, qkv_bias=False):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        assert d_model % num_heads == 0, \"d_model should be divisible by num_heads\"\n",
    "        \n",
    "        self.T = T\n",
    "        self.d_model =  d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_model // num_heads\n",
    "        self.Wq = nn.Linear(d_model, d_model, bias=qkv_bias)\n",
    "        self.Wk = nn.Linear(d_model, d_model, bias=qkv_bias)\n",
    "        self.Wv = nn.Linear(d_model, d_model, bias=qkv_bias)\n",
    "\n",
    "        self.dropout = nn.Dropout(drop_rate)\n",
    "        self.out_proj = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, T, embed_size)   # embed_size == d_model\n",
    "        B = x.shape[0]\n",
    "\n",
    "        queries = self.Wq(x)   # (B, T, d_model)\n",
    "        keys = self.Wk(x)   # (B, T, d_model)\n",
    "        values = self.Wv(x)   # (B, T, d_model)\n",
    "\n",
    "        # Divide d_model in num_heads\n",
    "        queries = queries.view(B, self.T, self.num_heads, self.head_dim)   # (B, T, num_heads, head_dim)\n",
    "        keys = keys.view(B, self.T, self.num_heads, self.head_dim)   # (B, T, num_heads, head_dim)\n",
    "        values = values.view(B, self.T, self.num_heads, self.head_dim)   # (B, T, num_heads, head_dim)\n",
    "\n",
    "        queries = queries.transpose(1, 2)   # (B, num_heads, T, head_dim)\n",
    "        keys = keys.transpose(1, 2)   # (B, num_heads, T, head_dim)\n",
    "        values = values.transpose(1, 2)   # (B, num_heads, T, head_dim)\n",
    "        \n",
    "        # Compute attention scores\n",
    "        attention_scores = queries @ keys.transpose(2, 3)   # (B, num_heads, T, T)\n",
    "\n",
    "        # Compute attention weights\n",
    "        mask = torch.triu(torch.ones(self.T, self.T), diagonal=1)   # (T, T)\n",
    "        masked_attention_scores = attention_scores.masked_fill(mask.bool(), -torch.inf)  # (B, num_heads, T, T)\n",
    "        attention_weights = torch.softmax( masked_attention_scores / keys.shape[-1] ** 0.5 , dim=-1)  # (B, num_heads, T, T)\n",
    "\n",
    "        # Compute context vector\n",
    "        Z = attention_weights @ values   # (B, num_heads, T, head_dim)\n",
    "        Z = Z.contiguous()\n",
    "        Z = Z.view(B, self.T, self.d_model)\n",
    "        Z = self.out_proj(Z)\n",
    "\n",
    "        return Z\n",
    "\n",
    "B = 2\n",
    "T = 4096\n",
    "d_model = 4608\n",
    "num_heads = 48\n",
    "drop_rate = 0.5\n",
    "X = torch.rand(B, T, d_model)\n",
    "multiheadattention = MultiHeadAttention(T, d_model, num_heads, drop_rate)\n",
    "out = multiheadattention(X)\n",
    "out.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e0d6a4e1-1608-4b7d-8442-15b3fed1f06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LayerNorm, self).__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(d_model))\n",
    "        self.shift = nn.Parameter(torch.zeros(d_model))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c99d3e13-2710-4487-9bea-4d97eec0ba50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GELU, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh( torch.sqrt(torch.tensor( 2.0 / torch.pi )) * (x + 0.044715 * torch.pow(x, 3)) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e2e4ba20-de7a-430f-bf96-e19fb0578e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardNetwork(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super(FeedForwardNetwork, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg['d_model'], 4 * cfg['d_model']),\n",
    "            GELU(),\n",
    "            nn.Linear(4 * cfg['d_model'], cfg['d_model']),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b8afa34f-1545-446e-8955-2fbed73da06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardNetwork(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super(FeedForwardNetwork, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg['d_model'], 4 * cfg['d_model']),\n",
    "            GELU(),\n",
    "            nn.Linear(4 * cfg['d_model'], cfg['d_model']),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "96880934-77f7-49c4-8c73-b918cb7c34f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:  torch.Size([2, 1024, 768])\n",
      "out:  torch.Size([2, 1024, 768])\n"
     ]
    }
   ],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.norm1 = LayerNorm()\n",
    "        self.norm2 = LayerNorm()\n",
    "        self.drop_resd = nn.Dropout(cfg['drop_rate'])\n",
    "        self.ffn = FeedForwardNetwork(cfg)\n",
    "        self.attn = MultiHeadAttention(T=cfg['context_length'],\n",
    "                                      d_model=cfg['d_model'],\n",
    "                                      num_heads=cfg['num_heads'],\n",
    "                                      drop_rate=cfg['drop_rate'],\n",
    "                                      qkv_bias=cfg['qkv_bias'])\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, T, embed_size)  embed_size == d_model\n",
    "        shortcut = x              # (B, T, d_model)\n",
    "        x = self.norm1(x)         # (B, T, d_model)\n",
    "        x = self.attn(x)           # (B, T, d_model)\n",
    "        x = self.drop_resd(x)     # (B, T, d_model)\n",
    "        x = x + shortcut          # (B, T, d_model)\n",
    "\n",
    "        shortcut = x\n",
    "        x = self.norm2(x)         # (B, T, d_model)\n",
    "        x = self.ffn(x)           # (B, T, d_model)\n",
    "        x = self.drop_resd(x)     # (B, T, d_model)\n",
    "        x = x + shortcut          # (B, T, d_model)\n",
    "\n",
    "        return x\n",
    "\n",
    "B = 2\n",
    "T = config['context_length']\n",
    "d_model = config['d_model']\n",
    "num_heads = config['num_heads']\n",
    "X = torch.rand(B, T, d_model)\n",
    "model = TransformerBlock(config)\n",
    "out = model(X)\n",
    "\n",
    "print('X: ', X.shape)\n",
    "print('out: ', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bdf2ed42-c4ea-4dbc-8080-6da4d8e26ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:  torch.Size([2, 1024])\n",
      "out:  torch.Size([2, 1024, 50257])\n"
     ]
    }
   ],
   "source": [
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super(GPTModel, self).__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg['vocab_size'], cfg['d_model'])\n",
    "        self.pos_emb = nn.Embedding(cfg['context_length'], cfg['d_model'])\n",
    "        self.dropout = nn.Dropout(cfg['drop_rate'])\n",
    "        self.transformer_blocks = nn.Sequential(*[TransformerBlock(cfg) for _ in range(cfg['num_layers'])])\n",
    "        self.final_norm = LayerNorm()\n",
    "        self.out_head = nn.Linear(cfg['d_model'], cfg['vocab_size'], bias=False)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # inputs: (B, T)\n",
    "        B, T = inputs.shape\n",
    "        tok_embeds = self.tok_emb(inputs)   # (B, d_model)\n",
    "        pos_embeds = self.pos_emb(torch.arange(T, device=inputs.device))  # (B, d_model)\n",
    "        x = tok_embeds + pos_embeds\n",
    "        x = self.dropout(x)\n",
    "        x = self.transformer_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits\n",
    "\n",
    "model = GPTModel(config)\n",
    "B = 2\n",
    "T = config['context_length']\n",
    "X = torch.randint(0, config['vocab_size'], (B, T))\n",
    "out = model(X)\n",
    "\n",
    "print('X: ', X.shape)\n",
    "print('out: ', out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e63ee9-51bd-447c-93ac-e6b4209a3b14",
   "metadata": {},
   "source": [
    "## Generating Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d541fc5e-0439-4201-9546-25ca8a2c26de",
   "metadata": {},
   "source": [
    "Converting tensor output of gpt model back into text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7ebe697b-6c24-457b-a0b6-cfeba714435b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, encoded_input, max_new_tokens, context_size):\n",
    "    for _ in range(max_new_tokens):\n",
    "        encode_input_context = encoded_input[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(encode_input_context)\n",
    "        logits = logits[:, -1, :]\n",
    "        probas = torch.softmax(logits, dim=-1)\n",
    "        encoded_input_next = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "        encoded_input = torch.cat((encoded_input, encoded_input_next), dim=1)\n",
    "\n",
    "    return encoded_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "95437719-a7e1-4f79-94d7-7fb35dc358f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1282])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "tok = tiktoken.get_encoding('gpt2')\n",
    "\n",
    "text1 = \"\"\"Mars is the fourth planet from the Sun. The surface of Mars is orange-red because it is covered in iron(III) oxide dust, giving it the nickname \"the Red Planet\".[21][22] Mars is among the brightest objects in Earth's sky and its high-contrast albedo features have made it a common subject for telescope viewing. It is classified as a terrestrial planet and is the second smallest of the Solar System's planets with a diameter of 6,779 km (4,212 mi). In terms of orbital motion, a Martian solar day (sol) is equal to 24.5 hours and a Martian solar year is equal to 1.88 Earth years (687 Earth days). Mars has two natural satellites that are small and irregular in shape: Phobos and Deimos.\n",
    "The relatively flat plains in northern parts of Mars strongly contrast with the cratered terrain in southern highlands – this terrain observation is known as the Martian dichotomy. Mars hosts many enormous extinct volcanos (such as Olympus Mons, 21.9 km or 13.6 mi tall) and one of the largest canyons in the Solar System (Valles Marineris, 4,000 km or 2,500 mi long). Geologically, the planet is fairly active with marsquakes trembling underneath the ground, dust devils sweeping across the landscape, and cirrus clouds. Carbon dioxide is substantially present in Mars's polar ice caps and thin atmosphere. During a year, there are large surface temperature swings on the surface between −78.5 °C (−109.3 °F) to 5.7 °C (42.3 °F)[c] similar to Earth's seasons, as both planets have significant axial tilt.\n",
    "Mars was formed approximately 4.5 billion years ago. During the Noachian period (4.5 to 3.5 billion years ago), Mars's surface was marked by meteor impacts, valley formation, erosion, and the possible presence of water oceans. The Hesperian period (3.5 to 3.3–2.9 billion years ago) was dominated by widespread volcanic activity and flooding that carved immense outflow channels. The Amazonian period, which continues to the present, was marked by the wind as a dominant influence on geological processes. Due to Mars's geological history, the possibility of past or present life on Mars remains of great scientific interest.\n",
    "Since the late 20th century, Mars has been explored by uncrewed spacecraft and rovers, with the first flyby by the Mariner 4 probe in 1965, the first Mars orbiter by the Mars 2 probe in 1971, and the first landing by the Viking 1 probe in 1976. As of 2023, there are at least 11 active probes orbiting Mars or at the Martian surface. Mars is an attractive target for future human exploration missions, though in the 2020s no such mission is planned.\n",
    "Scientists have theorized that during the Solar System's formation, Mars was created as the result of a random process of run-away accretion of material from the protoplanetary disk that orbited the Sun. Mars has many distinctive chemical features caused by its position in the Solar System. Elements with comparatively low boiling points, such as chlorine, phosphorus, and sulfur, are much more common on Mars than on Earth; these elements were probably pushed outward by the young Sun's energetic solar wind.[23]\n",
    "After the formation of the planets, the inner Solar System may have been subjected to the so-called Late Heavy Bombardment. About 60% of the surface of Mars shows a record of impacts from that era,[24][25][26] whereas much of the remaining surface is probably underlain by immense impact basins caused by those events. However, more recent modelling has disputed the existence of the Late Heavy Bombardment.[27] There is evidence of an enormous impact basin in the Northern Hemisphere of Mars, spanning 10,600 by 8,500 kilometres (6,600 by 5,300 mi), or roughly four times the size of the Moon's South Pole–Aitken basin, which would be the largest impact basin yet discovered if confirmed.[28] It has been hypothesized that the basin was formed when Mars was struck by a Pluto-sized body about four billion years ago. The event, thought to be the cause of the Martian hemispheric dichotomy, created the smooth Borealis basin that covers 40% of the planet.[29][30]\n",
    "A 2023 study shows evidence, based on the orbital inclination of Deimos (a small moon of Mars), that Mars may once have had a ring system 3.5 billion years to 4 billion years ago.[31] This ring system may have been formed from a moon, 20 times more massive than Phobos, orbiting Mars billions of years ago; and Phobos would be a remnant of that ring.[32][33]\n",
    "The geological history of Mars can be split into many periods, but the following are the three primary periods:[34][35]\n",
    "Noachian period: Formation of the oldest extant surfaces of Mars, 4.5 to 3.5 billion years ago. Noachian age surfaces are scarred by many large impact craters. The Tharsis bulge, a volcanic upland, is thought to have formed during this period, with extensive flooding by liquid water late in the period. Named after Noachis Terra.[36]\n",
    "Hesperian period: 3.5 to between 3.3 and 2.9 billion years ago. The Hesperian period is marked by the formation of extensive lava plains. Named after Hesperia Planum.[36]\n",
    "Amazonian period: between 3.3 and 2.9 billion years ago to the present. Amazonian regions have few meteorite impact craters but are otherwise quite varied. Olympus Mons formed during this period, with lava flows elsewhere on Mars. Named after Amazonis Planitia.[36]\n",
    "Geological activity is still taking place on Mars. The Athabasca Valles is home to sheet-like lava flows created about 200 million years ago. Water flows in the grabens called the Cerberus Fossae occurred less than 20 million years ago, indicating equally recent volcanic intrusions.[37] The Mars Reconnaissance Orbiter has captured images of avalanches.\"\"\"\n",
    "encoded = torch.tensor(tok.encode(text1)).unsqueeze(0)\n",
    "\n",
    "model.eval()\n",
    "out = generate_text(model, encoded, max_new_tokens=5, context_size=config['context_length'])\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8aaa5f5d-1ba6-4e13-a7cf-067310bd901e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mars is the fourth planet from the Sun. The surface of Mars is orange-red because it is covered in iron(III) oxide dust, giving it the nickname \"the Red Planet\".[21][22] Mars is among the brightest objects in Earth\\'s sky and its high-contrast albedo features have made it a common subject for telescope viewing. It is classified as a terrestrial planet and is the second smallest of the Solar System\\'s planets with a diameter of 6,779 km (4,212 mi). In terms of orbital motion, a Martian solar day (sol) is equal to 24.5 hours and a Martian solar year is equal to 1.88 Earth years (687 Earth days). Mars has two natural satellites that are small and irregular in shape: Phobos and Deimos.\\nThe relatively flat plains in northern parts of Mars strongly contrast with the cratered terrain in southern highlands – this terrain observation is known as the Martian dichotomy. Mars hosts many enormous extinct volcanos (such as Olympus Mons, 21.9 km or 13.6 mi tall) and one of the largest canyons in the Solar System (Valles Marineris, 4,000 km or 2,500 mi long). Geologically, the planet is fairly active with marsquakes trembling underneath the ground, dust devils sweeping across the landscape, and cirrus clouds. Carbon dioxide is substantially present in Mars\\'s polar ice caps and thin atmosphere. During a year, there are large surface temperature swings on the surface between −78.5 °C (−109.3 °F) to 5.7 °C (42.3 °F)[c] similar to Earth\\'s seasons, as both planets have significant axial tilt.\\nMars was formed approximately 4.5 billion years ago. During the Noachian period (4.5 to 3.5 billion years ago), Mars\\'s surface was marked by meteor impacts, valley formation, erosion, and the possible presence of water oceans. The Hesperian period (3.5 to 3.3–2.9 billion years ago) was dominated by widespread volcanic activity and flooding that carved immense outflow channels. The Amazonian period, which continues to the present, was marked by the wind as a dominant influence on geological processes. Due to Mars\\'s geological history, the possibility of past or present life on Mars remains of great scientific interest.\\nSince the late 20th century, Mars has been explored by uncrewed spacecraft and rovers, with the first flyby by the Mariner 4 probe in 1965, the first Mars orbiter by the Mars 2 probe in 1971, and the first landing by the Viking 1 probe in 1976. As of 2023, there are at least 11 active probes orbiting Mars or at the Martian surface. Mars is an attractive target for future human exploration missions, though in the 2020s no such mission is planned.\\nScientists have theorized that during the Solar System\\'s formation, Mars was created as the result of a random process of run-away accretion of material from the protoplanetary disk that orbited the Sun. Mars has many distinctive chemical features caused by its position in the Solar System. Elements with comparatively low boiling points, such as chlorine, phosphorus, and sulfur, are much more common on Mars than on Earth; these elements were probably pushed outward by the young Sun\\'s energetic solar wind.[23]\\nAfter the formation of the planets, the inner Solar System may have been subjected to the so-called Late Heavy Bombardment. About 60% of the surface of Mars shows a record of impacts from that era,[24][25][26] whereas much of the remaining surface is probably underlain by immense impact basins caused by those events. However, more recent modelling has disputed the existence of the Late Heavy Bombardment.[27] There is evidence of an enormous impact basin in the Northern Hemisphere of Mars, spanning 10,600 by 8,500 kilometres (6,600 by 5,300 mi), or roughly four times the size of the Moon\\'s South Pole–Aitken basin, which would be the largest impact basin yet discovered if confirmed.[28] It has been hypothesized that the basin was formed when Mars was struck by a Pluto-sized body about four billion years ago. The event, thought to be the cause of the Martian hemispheric dichotomy, created the smooth Borealis basin that covers 40% of the planet.[29][30]\\nA 2023 study shows evidence, based on the orbital inclination of Deimos (a small moon of Mars), that Mars may once have had a ring system 3.5 billion years to 4 billion years ago.[31] This ring system may have been formed from a moon, 20 times more massive than Phobos, orbiting Mars billions of years ago; and Phobos would be a remnant of that ring.[32][33]\\nThe geological history of Mars can be split into many periods, but the following are the three primary periods:[34][35]\\nNoachian period: Formation of the oldest extant surfaces of Mars, 4.5 to 3.5 billion years ago. Noachian age surfaces are scarred by many large impact craters. The Tharsis bulge, a volcanic upland, is thought to have formed during this period, with extensive flooding by liquid water late in the period. Named after Noachis Terra.[36]\\nHesperian period: 3.5 to between 3.3 and 2.9 billion years ago. The Hesperian period is marked by the formation of extensive lava plains. Named after Hesperia Planum.[36]\\nAmazonian period: between 3.3 and 2.9 billion years ago to the present. Amazonian regions have few meteorite impact craters but are otherwise quite varied. Olympus Mons formed during this period, with lava flows elsewhere on Mars. Named after Amazonis Planitia.[36]\\nGeological activity is still taking place on Mars. The Athabasca Valles is home to sheet-like lava flows created about 200 million years ago. Water flows in the grabens called the Cerberus Fossae occurred less than 20 million years ago, indicating equally recent volcanic intrusions.[37] The Mars Reconnaissance Orbiter has captured images of avalanches. rog traveled expressed ambiguity curiosity'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_text = tok.decode(out.squeeze(0).tolist())\n",
    "decoded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22a256d-38fc-4026-81c1-3d065cfaa742",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
